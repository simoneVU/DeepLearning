# Deep Learning

This repository contains the backpropagation implementation for a simple feed-forward network, with a cross-entropy loss function. It entirely implemented from scratch, using only
basic python primitives. Then, the forward and backward passes are vectorized with numpy and the results are compared.

## Experimental Setup

In order to run the experiments you need to have installed Python, matplolib and Numpy.
The following experiment can be run for digit recognotion with MNIST:

- [Mini-batch non-vectorized](https://github.com/simoneVU/DeepLearning/tree/main/Deep%20Learning%201)
- [Gradient Descent non-vectorized](https://github.com/simoneVU/DeepLearning/blob/main/Deep%20Learning%201/training_MNIST_SGD.py)
- [One-pass forward-backward](https://github.com/simoneVU/DeepLearning/blob/main/Deep%20Learning%201/training_simple.py)
- [Synthetic data training with SGD](https://github.com/simoneVU/DeepLearning/blob/main/Deep%20Learning%201/traning_synth.py)
